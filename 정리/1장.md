# 신뢰할 수 있고 확장 가능하며 유지보수 하기 쉬운 애플리케이션
> 오늘날 많은 어플리케이션은 환경이 좋아지면서 Compute-intensive 한 시스템 보다 Data-intensive한 환경으로 넘어가고 있다. 컴퓨터의 성능이야 시스템의 성능을 올리면 단순하게 해결되는 문제이지만, 데이터 양, 복잡도, 빠르게 변화한다면 그에 대해 대응하기는 쉽지 않다. 1장에서는 비기능적 요구사항 중 3가지 요소를 살펴 본다.

## 신뢰성 (Reliability)
- 사용자가 기대한 기능을 수행
- 예상치 못한 사용법을 허용
- 예상된 Traffic 속에서 잘 작동
- 예상된 Traffic 속에서 잘 작동

무언가가 잘못되더라도 지속적으로 올바르게 동작한다는 것을 Reliability로 볼 수 있다. 잘못될 수 있는 일을 Fault라고 불리며 이것을 사전에 예측하고 대처할 수 있는 것을 Fault-tolerant or Resilient를 가지고 있다 라고 말할 수 있다. 이것은 Failure와 다르다. Failure는 예측하지 못하고 사용자에게 서비스를 제공하지 못하고 시스템 전체가 멈춘 상태라고 말할 수 있다.

### Chaos Monkey
고의적으로 결함을 만들어 내면서 내결함성을 테스트하여, 실제 결함이 발생했을 때 올바르게 처리할 수 있는 방법

### 하드웨어 결함
하드디스크가 망가지거나, 램에 결함이 발생하거나, 대규모 정전 사태, 휴먼 에러들이 이에 포함된다. 보통 이를 해결하기 위해 하드웨어를 중복으로 설치하거나, 소프트웨어 자체에 Fault-tolerant을 내재한다.

### 소프트웨어 오류
하드웨어 결함은 다행스럽게 무작위적이고 서로 독립적이지만, 소프트웨어 오류는 그렇지 않다.
- 커널 버그로 인해 인스턴스가 죽음
- 로직의 오류로 시트템의 자원을 과도하게 남용
- 반응이 없거나 잘못된 응답을 함
- 하나의 작은 결함이 스노우 볼을 일으켜 연쇄 장애를 발생(cascading failure)

이러한 문제는 처음에 발견되지 않다가 어느 순간 발생할 가능성이 있다. 적절한 설계 및 모니터링을 잘 해주면 어느정도 문제 해결에 도움을 받을 수 있다.

### 인적 오류
사람이 소프트웨어를 개발하고 운영한다. 그리고 사람의 따라 역량이 다르기 때문에, 다양한 접근 방법을 둬야한다.
- 오류의 가능성이 최소화하는 시스템으로 설계하라. (Simple is best)
- 사람이 가장 실수하기 쉬운 부분을 파악하고 분리하라. 실제 데이터를 안전하게 테스트할 수 있지만 실 사용자에게 영향을 주지 않는 Sandbox를 제공하라
- Unit Test부터 End-to-End Test까지 철저하게 하라
- 장애 발생의 역량을 최소화 하기 위해 쉽게 복구 할 수 있도록 해야한다. (Runbook 등과 같은)
- 성능 지표나 오류율 같은 상세하고 명확한 모니터링 대책을 마련해라.
- KT를 많이 가져라. 

신뢰성은 매우 중요하지만, 이를 모두 지키려면 많은 비용으로 매출에 문제가 될 수 있다. 적절한 합의를 하여 시스템의 신뢰성을 높히도록 하자.

## 확장성 (Scailability)
시스템이 현재는 잘 작동한다고 해서 미래에도 안정적으로 동작한다는 보장은 없다. 지금 사용자가 1만명 일지라도 나중에 100만 명 또는 1000만 명으로 늘어날 수 있다. 늘어난 traffic에 대해 어떻게 대처해야할까?

### 예측되는 부하를 서술하기
시스템의 현 부하를 간결하게 서술할 수 있어야 한다. 그래야 증가하는 부하에 대해 논의할 수 있게 된다. 우리가 서술할 수 있는 매개변수는 다음과 같다.
- 초당 요청 수
- DB의 읽기/쓰기 비율
- 동시 사용자 수
- 캐시 적중률

Twitter에서는 처음 R-DB를 통해 Timeline을 사용자에게 보여줬는데, 점점 사용자 수가 늘어나자 서비스 부하를 감당하기 힘들어지기 시작한다. 쓰는 것에 비해 읽기 요청량이 많았기 때문에 시스템을 읽을 때 부하가 적은 방향으로 개선을 하였고 성능이 많이 개선되었다. 하지만, 엄청난 팔로우를 지닌 사람, 즉 스타들이 메시지를 하나 보내면 개선된 방향에서는 너무 많은 쓰기 작업이 발생했기 때문에 오히려 성능이 나빠지는 경우가 존재했다. 따라서 Twitter에서는 혼합된 방식을 적절히 사용하는 방향으로 갔다.

### 예측되는 성능을 서술하기
위에서 부하가 증가하면 어떤일이 일어날 수 있는지 Twitter의 케이스를 통해 보았다. 하지만 우리는 성능도 중요하다.
- 부하가 증가할 때 시스템 자원을 늘리지 않는다면 성능이 어떻게 될까?
- 부하가 증가할 때 성능이 지속되길 원한다면 시스템 자원을 얼마나 늘려야 할까?

이 질문에 답변하기 위해선 시스템 성능이 어느정도 되어야하는지 수치가 필요하다.

Hadoop과 같은 일괄 처리 시스템은 보통 처리량(Throughput)에 관심을 많이 가지며, 온라인 서비스에서는 응답 시간(Response time)에 관심을 많이 가진다.

#### 지연 시간 (Latency)과 응답 시간(Response time)
>이 둘은 종종 같은 의미로 사용하지만, 사실은 다른 의미이다. Response time은 클라이언트 입장에서 보는 시간이며, 실제 걸리는 시간과 여러 Delay값을 포함한다. 반면 지연 시간은 요청이 처리되길 기다리는 시간이다.

응답 시간 같은 경우 매번 클라이언트가 요청할 때마다 매번 응답시간이 다르다. 따라서, 응답 시간은 단순한 숫자가 아닌 분포를 보아야 한다. 평균 응답 시간에서 주로 산술 평균 값을 주소 사용하지만 이는 그렇게 좋은 값은 되지 못한다. 실제로 사용자가 얼마나 지연을 경험했는지 분포를 알 수 없기 때문이다. 그렇기 때문에 보통 평균 보다는 백분위 수(Percentile)를 자주 사용한다.

High percentiles(Tail Latency) 는 사용자 경험에 가장 큰 영향을 주기 때문에 매우 중요하다. 한번이라도 나쁜 경험을 한 고객은 만족도가 상당량 감소한다.

백분위는 SLO(Service Level Objective), SLA(Service Level Agreement) 에서도 상당히 중요하다. 특히 SLA에서 요구된 백분위를 지키지 못한 경우 고객이 환불을 요구할 수 있게 된다.

### 부하를 대응하는 법
예측되는 성능과 부하를 기술 할 수 있게 되었으니 그 다음 스텝은 부하를 어떻게 대응할 것인가? 이다. 보통 시스템을 확장할 때 사람들이 Scaling Up, Scaling Out이라는 말을 자주쓴다. Scailing Up은 서버의 수를 늘리는 것이 아닌 장비의 성능을 올리는 방법이며 Scaling Out은 장비의 성능을 올리는 것이 아닌 서버의 수를 늘리는 것이다. 요즘은 Scale Up보다는 Scale Out을 주로 한다. 왜냐하면 하드웨어 장애를 극복하기 위해서는 서버의 수가 많은 것이 유리하며 가격 측면에서도 훨씬 유리하기 때문이다. Scale Out할 때 Stateless한 서비스를 배포하는 것은 간단하다. 하지만 Stateful한 서비스를 확장하는 것은 상당히 어렵다. 왜냐하면 State를 관리한다는 것은 동시에 여러 장비의 동기화도 맞추어야 하며, Disk에 데이터를 저장하고 있었을 시 어떻게 그것을 관리할 것인가 고민을 해야하기 때문이다. 그래서 Stateful한 장비는 Scale out을 포기할 때도 있다. 

우리는 보통 범용적이고 어떤 상황에도 들어맞는 one-size-fits-all 아키텍처를 가져가고 싶어한다. 하지만 시스템의 데이터의 throughput, volume, complexity 그리고 응답 시간 등 여러 요소들을 고려해야한다.

예를 들어 우리가 서울에서 수원까지가는데 비행기를 타고 가지 않을 것이다. 모든 아키텍쳐는 적절한 아키텍쳐가 있고 그것 맞춰서 디자인 해야한다. 그리고 아직 검증되지 않은 먼 미래를 벌써부터 고민할 필요가 없다. 그때 그때 필요에 따라 성능을 개선해 나가면 된다.

## 유지보수성 (Maintainability)

시스템은 초기 개발 뿐만이 아닌 지속해서 이어지는 유지보수가 들어가야한다. 이런 유지보수에는 버그 수정, 시스템 운영 유지, 장애 조사, 새로운 플랫폼 적용, 새로운 사용 사례를 위한 변경, 기술 채무 상환 등이 있다. 많은 사람들이 레거시를 건드는 것을 좋아하지 않지만, 유지 보수의 고통을 최소화 하고 레거시 소프트웨어가 되지 않게끔 하는 방법이 있다. 그러기 위해선 3가지 요구 사항을 지켜야 한다.

- 운용성 (Operability) - 운영팀이 시스템을 원활하게 운영할 수 있게 쉽게 만들어라
- 단순성 (Simplicity) - 시스템의 복잡도를 최대한 제거해 새로운 엔지니어가 이해하기 쉽게 만들어라
- 발전성 (Evolvability) - 엔지니어가 이후에 시스템을 쉽게 변경할 수 있도록 해라. 예기치 못한 요구사항을 즉각적으로 고칠 수 있어야 한다.

### 운용성 : 운영을 편리하게..!
좋은 운영은 종종 불완전한 소프트웨어의 제약을 피하게 만든다.
- 좋은 모니터링으로 런타임 동작과 시스템의 내부의 Visibility 제공
- Standard Tool을 이용하여 자동화와 통합을 위한 우수한 지원을 제공
- 운영 환경의 의존성을 제거
- 좋은 문서와 이해하기 쉬운 운영 모델
- 만족할만한 기본 기능을 제공, 필요할 때 기본값을 다시 정의할 수 있어야 함
- 적절하게 자기 회복(self-healing) 뿐만이 아닌 관리자가 필요에 따라 시스템 상태를 수동으로 제어할 수 있게 해야함.
- 예측 가능하게 만들고 예기치 못한 상황을 최소화함

### 단순성: 복잡도 관리
소규모 프로젝트는 간단하게 표현이 풍부한 코드로 말끔하게 시스템을 작성할 수 있지만, 프로젝트가 커지면서 점점 시스템은 복잡해 진다. 복잡도 수렁에 빠진 소프트웨어 프로젝트는 때론 Big ball of mud로 묘사된다.

복잡도는 다양한 증상으로 나타난다. Explosion of the state space, Tight coupling of modules, Trangled dependencies, Inconsistent naming and terminology, Hack for solving performance issue, Special-casing to work around issues 등.. 

따라서 시스템은 최대한 간단하게 만드는 것이 중요하다. 단순하게 만든다는 것은 기능을 줄인다는 말은 아니며, Accidental Complexity를 줄여나가야 한다는 것이다.

이런 문제를 줄이기 위해 가장 좋은 것은 추상화이다. 적절한 추상화는 깔끔하고 직관적인 개발이 가능하다. 예를 들어 High-Level Language 는 복잡한 Machine Language, CPU Register, System Call등을 숨긴 추상화다.

### 발전성: 쉽게 변하게 만들자
요구사항이 영원이 바뀌지 않을 가능성을 매우 낮다. 시스템의 요구사항이 끊임없이 변할 가능성이 훨씬 크다. 그러기 위해 TDD, Refactoring은 이러한 소프트웨어 개발 방식에 매우 부합하다.

오늘의 영상: https://www.youtube.com/watch?v=mNPpfB8JSIU&list=WL&index=50

